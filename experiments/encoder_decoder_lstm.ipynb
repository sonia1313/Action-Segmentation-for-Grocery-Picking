{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from utils.optoforce_data_loader import load_data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.preprocessing import *\n",
    "from utils.preprocessing import remove_padding\n",
    "from models.encoder_decoder_lstm import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PATH_TO_DIR = 'C:/Users/sonia/OneDrive - Queen Mary, University of London/Action-Segmentation-Project'\n",
    "# X_data, y_data, _ = preprocess_dataset(PATH_TO_DIR)\n",
    "# train_loader, val_loader, test_loader = load_data(X_data,y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#X, y = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  4,  4,  4,  4,  4,\n         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  3,  2,  2,  2,  5,\n         5,  5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    \"\"\" Encodes tactile time series data \"\"\"\n",
    "\n",
    "    def __init__(self, n_features =3, hidden_size=100, n_layers=1, n_classes=6):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.n_features, hidden_size=self.hidden_size,\n",
    "                            num_layers=self.n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # print(f\"encoder hidden shape {h_n.shape}\")\n",
    "        # print(f\"encoder cell shape {c_n.shape}\")\n",
    "        #\n",
    "        # print(f\"output shape {output.shape}\")\n",
    "        return h_n,c_n\n",
    "\n",
    "    # def _init_states(self, batch_size):\n",
    "    #     if torch.cuda.is_available():\n",
    "    #         h0 = torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True, device=\"cuda\")\n",
    "    #         # c0 = torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True, device=\"cuda\")\n",
    "    #\n",
    "    #     else:\n",
    "    #         h0 = torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True)\n",
    "    #         # c0 = torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True)\n",
    "    #\n",
    "    #     return h0, c0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class DecoderLSTM(torch.nn.Module):\n",
    "    def __init__(self, hidden_size =100, n_classes=6):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.lstm = nn.LSTM(1, self.hidden_size)\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=self.n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        \"\"\"\"\n",
    "        hidden - the final hidden state from the encoder model is the context vector of the source sequence.\n",
    "        x - is the target ouput\n",
    "\n",
    "        \"\"\"\n",
    "        #x = x.unsqueeze(0)\n",
    "        #print(\"adding extra dimension in decoder input\")\n",
    "        #x = torch.LongTensor(x.view(1,1,1))\n",
    "        #\n",
    "        # print(f\"decoder input shape: {x.shape}\")\n",
    "        #lstm input size: (seq_len, batch,n_features) = (1,1,1)\n",
    "        # print(f\"decoder input: {x}\")\n",
    "        # print(f\"decoder hidden input shape: {hidden.shape}\")\n",
    "        # print(f\"decoder cell input shape : {cell.shape}\")\n",
    "        output, (hidden,cell) = self.lstm(x, (hidden, cell))\n",
    "        #output shape: (1,1,100)\n",
    "\n",
    "        # print(f\"decoder output shape: {output.shape}\")\n",
    "        # print(f\"decoder hidden shape: {hidden.shape}\")\n",
    "        # print(f\"decoder cell shape: {hidden.shape}\")\n",
    "\n",
    "\n",
    "        flatten_output = output.view(-1, output.shape[2])\n",
    "\n",
    "        # print(f\"flatten output shape:  {flatten_output.shape} \")\n",
    "        #flatten_output shape: (1, 100)\n",
    "        logits = self.linear(flatten_output)\n",
    "        #shape of logits: (1,6)\n",
    "\n",
    "        # print(f\"logits shape:{logits.shape}\")\n",
    "\n",
    "        return logits, hidden,cell\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# t = torch.rand(1,3)\n",
    "# print(t)\n",
    "# out = t.argmax(-1)\n",
    "# print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderLSTM()\n",
    "        self.decoder = DecoderLSTM()\n",
    "\n",
    "        assert self.encoder.hidden_size == self.decoder.hidden_size\n",
    "\n",
    "\n",
    "    def forward(self,x,y, teacher_forcing_ratio, n_classes = 6):\n",
    "\n",
    "        batch_size = y.shape[0]\n",
    "        optoforce_seq_len = y.shape[1]\n",
    "\n",
    "        outputs = torch.zeros(batch_size,optoforce_seq_len,n_classes)\n",
    "\n",
    "        hidden, cell = self.encoder(x)\n",
    "        # print(\"context vector shape\")\n",
    "        # print(hidden.shape)\n",
    "        #decoder_input = torch.zeros((1,1,1)) #not sure\n",
    "        # print(\"beginning decoder input\")\n",
    "        # print(decoder_input.shape)\n",
    "        decoder_input = y[0][0]\n",
    "        decoder_input = decoder_input.type(torch.float32)\n",
    "        decoder_input = decoder_input.view(1,1,1)\n",
    "        for t in range(1,optoforce_seq_len):\n",
    "            #print(t)\n",
    "            # print(f\"decoder input shape at time {t} = {decoder_input.shape}\")\n",
    "            # print(f\"h_x.shape {hidden.shape}\")\n",
    "            # print(f\"cell.shape {cell.shape}\")\n",
    "            #print(f\"current t {t}\")\n",
    "            output, hidden, cell  = self.decoder(decoder_input, hidden, cell)\n",
    "            #output shape (1,6)\n",
    "\n",
    "            # print(f\"output predicted at time {t} = {output}\")\n",
    "            outputs[0][t-1] = output\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # print(f\"teacher forcing present at time {t} = {teacher_force}\")\n",
    "            top_pred = output.argmax(-1)\n",
    "            #print(f\"top predicition at time {t} = {top_pred}\")\n",
    "            decoder_input = y[0][t] if teacher_force else top_pred\n",
    "\n",
    "            #print(f\"getting decoder input from time {t}\")\n",
    "            decoder_input = decoder_input.type(torch.float32)\n",
    "            decoder_input = decoder_input.view(1,1,1)\n",
    "            #print(f\"next input at time {t} = {decoder_input.shape}, {decoder_input}\")\n",
    "            #\n",
    "\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# encoder = EncoderLSTM()\n",
    "# decoder = DecoderLSTM()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# hidden,cell = encoder(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# t_1 = y[0][1]\n",
    "# t_1 = t_1.type(torch.float32)\n",
    "# t_1 = t_1.view(1,1,1)\n",
    "# print(t_1)\n",
    "#\n",
    "# t_1.dtype"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# t_0 = torch.zeros([1,1,1]) #seq_len x batch_size x n_features\n",
    "# t_0.dtype\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# d_logits,d_hidden,d_cell = decoder(t_0,hidden,cell)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# d_logits,d_hidden,d_cell = decoder(t_1,d_hidden,d_cell)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# y.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# outputs = torch.zeros(y.shape[0],y.shape[1],6)\n",
    "#\n",
    "# outputs[0][1] = d_logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# print(outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from utils.optoforce_datamodule import OpToForceDataModule, KFoldLoop\n",
    "class LitEncoderDecoderLSTM(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_decoder_model = EncoderDecoderLSTM()\n",
    "        self.loss_module = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "        self.train_acc = Accuracy(ignore_index=-1)\n",
    "        self.val_acc = Accuracy(ignore_index=-1)\n",
    "        self.test_acc = Accuracy(ignore_index=-1)\n",
    "\n",
    "    def forward(self,X,y,teacher_forcing):\n",
    "        logits = self.encoder_decoder_model(X,y,teacher_forcing)\n",
    "        return logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "\n",
    "        logits, loss = self._get_preds_and_loss(X,y,teacher_forcing=0.5)\n",
    "        train_perplexity = torch.exp(loss)\n",
    "        #logits shape : (n_timesteps, n_classes)\n",
    "        self.train_acc(logits,y.squeeze(0)) #remove batch dimension\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_PPL', train_perplexity, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "\n",
    "        logits, val_loss = self._get_preds_and_loss(X,y,teacher_forcing=0.0)\n",
    "\n",
    "        val_perplexity = torch.exp(val_loss)\n",
    "        self.val_acc(logits, y.squeeze(0))\n",
    "\n",
    "        self.log('val_loss', val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.log('val_PPL', val_perplexity, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        #return val_loss\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "\n",
    "        logits, test_loss = self._get_preds_and_loss(X,y,teacher_forcing=0.0)\n",
    "\n",
    "        test_perplexity = torch.exp(test_loss)\n",
    "        self.test_acc(logits,y.squeeze(0)) #remove the batch dimension\n",
    "\n",
    "        self.log(\"test_loss\", test_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_PPL', test_perplexity, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        #return test_loss\n",
    "\n",
    "    def _get_preds_and_loss(self,X,y, teacher_forcing):\n",
    "\n",
    "        logits = self(X,y,teacher_forcing)\n",
    "        logits = logits.squeeze(0) #remove the batch dimension\n",
    "        loss = self.loss_module(logits,y.squeeze(0))\n",
    "\n",
    "        return logits , loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# encoder_decoder = EncoderDecoderLSTM(encoder,decoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# outputs = encoder_decoder(X,y,0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#outputs.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "#outputs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#outputs[0][0:101]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# element = 99\n",
    "#\n",
    "# y = [100,200,300]\n",
    "#\n",
    "# for i in range(1,len(y)+1):\n",
    "#     print(i)\n",
    "#     input = element*2\n",
    "#     print(input)\n",
    "#     element = y[i-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#trainer = pl.Trainer(default_root_dir=f\"{PATH_TO_DIR}/checkpoints\",  gpus=0, max_epochs=20, deterministic=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#model = LitEncoderDecoderLSTM()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#trainer.fit(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#trainer.test(dataloaders=test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                  | Type               | Params\n",
      "-------------------------------------------------------------\n",
      "0 | encoder_decoder_model | EncoderDecoderLSTM | 83.8 K\n",
      "1 | loss_module           | CrossEntropyLoss   | 0     \n",
      "2 | train_acc             | Accuracy           | 0     \n",
      "3 | val_acc               | Accuracy           | 0     \n",
      "4 | test_acc              | Accuracy           | 0     \n",
      "-------------------------------------------------------------\n",
      "83.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "83.8 K    Total params\n",
      "0.335     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING FOLD 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonia\\anaconda3\\envs\\action-seg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\sonia\\anaconda3\\envs\\action-seg\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1933: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\sonia\\anaconda3\\envs\\action-seg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97e37beec2b2424bacd0260d0a883812"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c82ec71cd6646038ac07c8a9c80eccf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5dfd544ba7204ce8b77747d1e9032435"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "089d3ee2348242db982f7d16a91bf10d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75b444030fb94650a22b4bd512b85766"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e28c2e361cc649c2b2f004a30af7034d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcf57f6aa9f6494981bdb3127535c08a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a20b3e355bd4f7385c94a1e66baa276"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94a51e3460754e3ab38848edcb66ed26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6283b6b0d2b46cb817aff7d647dcd64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb89c4f25a6e4860954eba03f7a745bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonia\\anaconda3\\envs\\action-seg\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfbdf2a61bf846c2b95aba5d3455691b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_PPL             6.95831298828125\r\n",
      "        test_acc            0.27234041690826416\r\n",
      "        test_loss           1.9365366697311401\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 2it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57b9626d8c9c4f4eb7db676a6185701e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88f9181786c54184a9f8de698ce201b0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebf1ad4fe85d40baae14708ec04c258b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a70e38b496a749908582958e77fdee7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f1b4ee7b9dd420187dab71ea64c9b3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "539f15cca31e44a29cc94e80dd8979a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83dee449d7244d5c811e42465713d147"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa40169283dc418494fe2b11d37b4cf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "870220c470eb4848a13995b219dc64e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "430066dfcd0f48d0aafb2c51d3c21cce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83b58765899a409295fed20111ec7d6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1c5ac6db38d43babeb2f94781b92c16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_PPL             5.466350555419922\r\n",
      "        test_acc            0.27234041690826416\r\n",
      "        test_loss           1.6984658241271973\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 2\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 2it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75a00cdcc96b4753bcc8cbc9f82493ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d464977583fd4e78b746a3b01729a108"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcf3d1907b044e04b8261d5af323f767"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e831ea7af7004119a507bb05e193974d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f96091cac3bc4a578c4dd05b2302b305"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a2937f7835e4968bbcab04ca7f6bf7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0a3a09313b04cc38df0c66a4cf28b02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0603b051e67d4405b158c3a15039a181"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29d1a7eb8e3d4bce879fed8d4decf1f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b1c85318f054db4beccecb1049572d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68489c7c24a84d25a967a16083424737"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0656493cee442c6b3ead4329749d0a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_PPL             5.853527069091797\r\n",
      "        test_acc            0.2851063907146454\r\n",
      "        test_loss           1.7611485719680786\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 2it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2134858a67e548f1a24721e1b24bba6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad2315e744224ffdaafc026123f8eff0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d771ccdabb3541afb51c37ad8840dc54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6157c257240a496c800b55e31d3e5914"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f36f3d477b64a4985d1918ab4105919"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ae1dd6bb2484918b2ce23cc78612269"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4f5aa3e1b794516aa98901757568c8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a15676e97394037b4dab0bb4c0ecd8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e13eee69b0a4c86a6b2b163b6d19daf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "417252f74f1145459888f6336020a51d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "418b80199ade45eb97f95f25ee48f22f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df74bc1dd1af4c5bad8811c8d2d0458d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_PPL             6.544190406799316\r\n",
      "        test_acc            0.27659574151039124\r\n",
      "        test_loss           1.8642303943634033\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "733d9f8113cd4a58b31588f3ef909f86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "    average test_acc        0.27234041690826416\r\n",
      "    average_test_loss       1.7213537693023682\r\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_DIR = 'C:/Users/sonia/OneDrive - Queen Mary, University of London/Action-Segmentation-Project'\n",
    "pl.seed_everything(42)\n",
    "X_data, y_data, labels_map = preprocess_dataset(PATH_TO_DIR)\n",
    "model = LitEncoderDecoderLSTM()\n",
    "datamodule = OpToForceDataModule(X_data,y_data)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    limit_train_batches=2,\n",
    "    limit_val_batches=2,\n",
    "    limit_test_batches=2,\n",
    "    num_sanity_val_steps=0,\n",
    "    #devices=2,\n",
    "    gpus=0,\n",
    "    accelerator=\"auto\",\n",
    "    #strategy=\"ddp\",\n",
    "\n",
    ")\n",
    "\n",
    "internal_fit_loop = trainer.fit_loop\n",
    "trainer.fit_loop = KFoldLoop(num_folds=4,export_path='testing_kfold')\n",
    "trainer.fit_loop.connect(internal_fit_loop)\n",
    "trainer.fit(model, datamodule)\n",
    "#trainer.test(datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}