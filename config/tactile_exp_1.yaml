#trained on GPU
experiment_name: tactile_exp_1
main_dir: C:/Users/sonia/OneDrive - Queen Mary, University of London/Action-Segmentation-Project

seed: 42

dataset:
  preprocess:
    data_path: dataset #get_files()
    clutter: True #get_files()
    single: True #get_files()
    frames_per_sec: 3 #30 #15 #30 #84 #15 #1 #15 #84 #read_data()
    feature_engineering: True #read_data()
    standardise_data: True #preprocess_dataset()
    normalize_data: False #preprocess_dataset()
    pad_data: True #preprocess_dataset()


model:
  module_name: encoder_decoder_lstm
  pl_class_name : LitEncoderDecoderLSTM
  script_path: models/encoder_decoder_lstm.py
  #set n_features according to preprocess dataset conditions
    #i.e. default is 3 (features = [index,thumb,middle] when feature engineering = True)
  n_features: 3
  n_layers: 1
  n_hidden_units: 200

train:
  checkpoint_path: logging
  batch_size: 1
  epochs: 10 #3 #20 #20 #5 #20 #25
#  kfold_path: cross-validation/encoder_decoder_kfold
#  n_kfolds: 5

# the author uses wieghts and biases for experiment tracking
#wb:
#  project: Tactile_Action_Segmentation
#  group: tactile_exp_1 #experiment name





