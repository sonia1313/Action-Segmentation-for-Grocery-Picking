# Action Segmentation from Human-Robot Demonstrations for Grocery Picking

This repo contains experiments and source code for work in Action Segmentation from Human-Robot Demonstrations for Grocery Picking by Sonia Mathews.
This work proposes a multimodal model that learns from human-robot demonstrations (RGB images and Haptic feedback) to apply action segmentation for pick and place systems. 

All Experiments are done in PyTorch and Pytorch Lightning.
