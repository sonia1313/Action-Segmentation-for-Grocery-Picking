{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "os.chdir(\"/content/drive/Othercomputers/Dell/Action-Segmentation-Project\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzBa903bz8wU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658141188745,
     "user_tz": -60,
     "elapsed": 21715,
     "user": {
      "displayName": "Sonia Mathews",
      "userId": "11348936089475052132"
     }
    },
    "outputId": "fcef29e6-54ad-4662-b995-e6c18c48fad7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/Othercomputers/Dell/Action-Segmentation-Project\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WO6c9KSz8wa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658141192743,
     "user_tz": -60,
     "elapsed": 281,
     "user": {
      "displayName": "Sonia Mathews",
      "userId": "11348936089475052132"
     }
    },
    "outputId": "f084c0ee-27d8-44b6-d810-14a83ffc65df"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n",
      "\u001B[K     |████████████████████████████████| 585 kB 5.1 MB/s \n",
      "\u001B[?25hCollecting PyYAML>=5.4\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001B[K     |████████████████████████████████| 596 kB 50.9 MB/s \n",
      "\u001B[?25hCollecting torchmetrics>=0.4.1\n",
      "  Downloading torchmetrics-0.9.2-py3-none-any.whl (419 kB)\n",
      "\u001B[K     |████████████████████████████████| 419 kB 58.2 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.64.0)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "\u001B[K     |████████████████████████████████| 140 kB 71.3 MB/s \n",
      "\u001B[?25hCollecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.1.1)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.17.3)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.8.0)\n",
      "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.12.0+cu113)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.1 MB 51.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.47.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.7)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.2.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001B[K     |████████████████████████████████| 271 kB 52.5 MB/s \n",
      "\u001B[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001B[K     |████████████████████████████████| 94 kB 2.8 MB/s \n",
      "\u001B[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001B[K     |████████████████████████████████| 144 kB 73.8 MB/s \n",
      "\u001B[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, pytorch-lightning\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 pyDeprecate-0.3.2 pytorch-lightning-1.6.5 torchmetrics-0.9.2 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-lightning\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "gJEFXwjHz8wb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658141203563,
     "user_tz": -60,
     "elapsed": 10092,
     "user": {
      "displayName": "Sonia Mathews",
      "userId": "11348936089475052132"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ea6eafe0-abbe-4afd-d813-848db7109b6d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[K     |████████████████████████████████| 1.8 MB 4.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 181 kB 71.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 147 kB 63.8 MB/s \n",
      "\u001B[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
      "\u001B[?25h  Building wheel for pathtools (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb -qU"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zUYPxRjCz8wc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658141211727,
     "user_tz": -60,
     "elapsed": 8173,
     "user": {
      "displayName": "Sonia Mathews",
      "userId": "11348936089475052132"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1fbd95b-e17c-410e-e078-19ea67890f18"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3XFNh8SoXLTW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import main_2\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kOR4Zqr5XLTW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Global seed set to 42\n",
      "Tesla P100-PCIE-16GB\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type               | Params\n",
      "-------------------------------------------------------------\n",
      "0 | encoder_decoder_model | EncoderDecoderLSTM | 83.8 K\n",
      "1 | loss_module           | CrossEntropyLoss   | 0     \n",
      "2 | train_acc             | Accuracy           | 0     \n",
      "3 | val_acc               | Accuracy           | 0     \n",
      "4 | test_acc              | Accuracy           | 0     \n",
      "-------------------------------------------------------------\n",
      "83.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "83.8 K    Total params\n",
      "0.335     Total estimated model params size (MB)\n",
      "STARTING FOLD 0\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1937: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n",
      "Epoch 0:   0% 0/4 [00:00<?, ?it/s] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 0: 100% 4/4 [00:01<00:00,  3.11it/s, loss=1.81, v_num=44, val_loss=1.790, val_acc=0.192, val_PPL=5.990]\n",
      "Epoch 1:   0% 0/4 [00:00<?, ?it/s, loss=1.81, v_num=44, val_loss=1.790, val_acc=0.192, val_PPL=5.990, train_acc=0.070, train_PPL=6.130]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1: 100% 4/4 [00:00<00:00, 12.09it/s, loss=1.8, v_num=44, val_loss=1.770, val_acc=0.192, val_PPL=5.880, train_acc=0.070, train_PPL=6.130] \n",
      "Epoch 2:   0% 0/4 [00:00<?, ?it/s, loss=1.8, v_num=44, val_loss=1.770, val_acc=0.192, val_PPL=5.880, train_acc=0.162, train_PPL=6.020]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2: 100% 4/4 [00:00<00:00, 12.69it/s, loss=1.8, v_num=44, val_loss=1.770, val_acc=0.226, val_PPL=5.850, train_acc=0.162, train_PPL=6.020]\n",
      "Epoch 3:   0% 0/4 [00:00<?, ?it/s, loss=1.8, v_num=44, val_loss=1.770, val_acc=0.226, val_PPL=5.850, train_acc=0.162, train_PPL=5.920]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3: 100% 4/4 [00:00<00:00, 12.03it/s, loss=1.79, v_num=44, val_loss=1.770, val_acc=0.241, val_PPL=5.850, train_acc=0.162, train_PPL=5.920]\n",
      "Epoch 4:   0% 0/4 [00:00<?, ?it/s, loss=1.79, v_num=44, val_loss=1.770, val_acc=0.241, val_PPL=5.850, train_acc=0.157, train_PPL=5.880]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4: 100% 4/4 [00:00<00:00, 12.48it/s, loss=1.79, v_num=44, val_loss=1.770, val_acc=0.276, val_PPL=5.870, train_acc=0.157, train_PPL=5.880]\n",
      "Epoch 5:   0% 0/4 [00:00<?, ?it/s, loss=1.79, v_num=44, val_loss=1.770, val_acc=0.276, val_PPL=5.870, train_acc=0.331, train_PPL=5.860]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5: 100% 4/4 [00:00<00:00, 12.34it/s, loss=1.78, v_num=44, val_loss=1.750, val_acc=0.276, val_PPL=5.780, train_acc=0.331, train_PPL=5.860]\n",
      "Epoch 6:   0% 0/4 [00:00<?, ?it/s, loss=1.78, v_num=44, val_loss=1.750, val_acc=0.276, val_PPL=5.780, train_acc=0.370, train_PPL=5.760]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6: 100% 4/4 [00:00<00:00, 11.94it/s, loss=1.77, v_num=44, val_loss=1.740, val_acc=0.276, val_PPL=5.670, train_acc=0.370, train_PPL=5.760]\n",
      "Epoch 7:   0% 0/4 [00:00<?, ?it/s, loss=1.77, v_num=44, val_loss=1.740, val_acc=0.276, val_PPL=5.670, train_acc=0.370, train_PPL=5.620]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7: 100% 4/4 [00:00<00:00, 11.91it/s, loss=1.76, v_num=44, val_loss=1.710, val_acc=0.276, val_PPL=5.520, train_acc=0.370, train_PPL=5.620]\n",
      "Epoch 8:   0% 0/4 [00:00<?, ?it/s, loss=1.76, v_num=44, val_loss=1.710, val_acc=0.276, val_PPL=5.520, train_acc=0.370, train_PPL=5.500]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 8: 100% 4/4 [00:00<00:00, 12.51it/s, loss=1.75, v_num=44, val_loss=1.660, val_acc=0.276, val_PPL=5.270, train_acc=0.370, train_PPL=5.500]\n",
      "Epoch 9:   0% 0/4 [00:00<?, ?it/s, loss=1.75, v_num=44, val_loss=1.660, val_acc=0.276, val_PPL=5.270, train_acc=0.370, train_PPL=5.250]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9: 100% 4/4 [00:00<00:00, 12.05it/s, loss=1.73, v_num=44, val_loss=1.600, val_acc=0.276, val_PPL=4.960, train_acc=0.370, train_PPL=5.250]\n",
      "Epoch 9: 100% 4/4 [00:00<00:00, 11.33it/s, loss=1.73, v_num=44, val_loss=1.600, val_acc=0.276, val_PPL=4.960, train_acc=0.370, train_PPL=4.770]\n",
      "Testing DataLoader 0: 100% 2/2 [00:00<00:00, 17.70it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_PPL             4.863716125488281\n",
      "        test_acc            0.3520408272743225\n",
      "        test_loss           1.5808260440826416\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 1\n",
      "Epoch 0:   0% 0/4 [00:00<00:00, -15768.06it/s] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 14.19it/s]\u001B[A\n",
      "Epoch 0: 100% 4/4 [00:00<00:00,  4.70it/s, loss=1.73, v_num=44, val_loss=1.800, val_acc=0.146, val_PPL=6.040, train_acc=0.370, train_PPL=4.770, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 1:   0% 0/4 [00:00<00:00, -5694.91it/s, loss=1.73, v_num=44, val_loss=1.800, val_acc=0.146, val_PPL=6.040, train_acc=0.0766, train_PPL=6.100, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00,  7.08it/s]\u001B[A\n",
      "Epoch 1: 100% 4/4 [00:00<00:00,  2.44it/s, loss=1.73, v_num=44, val_loss=1.780, val_acc=0.162, val_PPL=5.930, train_acc=0.0766, train_PPL=6.100, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 2:   0% 0/4 [00:00<00:00, -6955.73it/s, loss=1.73, v_num=44, val_loss=1.780, val_acc=0.162, val_PPL=5.930, train_acc=0.153, train_PPL=6.030, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 15.95it/s]\u001B[A\n",
      "Epoch 2: 100% 4/4 [00:00<00:00,  4.13it/s, loss=1.73, v_num=44, val_loss=1.770, val_acc=0.305, val_PPL=5.900, train_acc=0.153, train_PPL=6.030, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 3:   0% 0/4 [00:00<00:00, -8035.07it/s, loss=1.73, v_num=44, val_loss=1.770, val_acc=0.305, val_PPL=5.900, train_acc=0.253, train_PPL=5.970, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 16.81it/s]\u001B[A\n",
      "Epoch 3: 100% 4/4 [00:00<00:00,  4.43it/s, loss=1.73, v_num=44, val_loss=1.750, val_acc=0.308, val_PPL=5.780, train_acc=0.253, train_PPL=5.970, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 4:   0% 0/4 [00:00<00:00, -8305.55it/s, loss=1.73, v_num=44, val_loss=1.750, val_acc=0.308, val_PPL=5.780, train_acc=0.322, train_PPL=5.920, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 16.44it/s]\u001B[A\n",
      "Epoch 4: 100% 4/4 [00:00<00:00,  4.44it/s, loss=1.73, v_num=44, val_loss=1.730, val_acc=0.322, val_PPL=5.660, train_acc=0.322, train_PPL=5.920, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 5:   0% 0/4 [00:00<00:00, -7847.15it/s, loss=1.73, v_num=44, val_loss=1.730, val_acc=0.322, val_PPL=5.660, train_acc=0.337, train_PPL=5.830, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 14.77it/s]\u001B[A\n",
      "Epoch 5: 100% 4/4 [00:00<00:00,  4.45it/s, loss=1.73, v_num=44, val_loss=1.710, val_acc=0.325, val_PPL=5.500, train_acc=0.337, train_PPL=5.830, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 6:   0% 0/4 [00:00<00:00, -7810.62it/s, loss=1.73, v_num=44, val_loss=1.710, val_acc=0.325, val_PPL=5.500, train_acc=0.352, train_PPL=5.720, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6: 100% 4/4 [00:00<00:00,  5.45it/s, loss=1.73, v_num=44, val_loss=1.670, val_acc=0.325, val_PPL=5.310, train_acc=0.352, train_PPL=5.720, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 7:   0% 0/4 [00:00<00:00, -9565.12it/s, loss=1.73, v_num=44, val_loss=1.670, val_acc=0.325, val_PPL=5.310, train_acc=0.360, train_PPL=5.600, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7: 100% 4/4 [00:00<00:00,  6.21it/s, loss=1.73, v_num=44, val_loss=1.620, val_acc=0.325, val_PPL=5.070, train_acc=0.360, train_PPL=5.600, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 8:   0% 0/4 [00:00<00:00, -11798.32it/s, loss=1.73, v_num=44, val_loss=1.620, val_acc=0.325, val_PPL=5.070, train_acc=0.360, train_PPL=5.480, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 8: 100% 4/4 [00:00<00:00,  6.11it/s, loss=1.73, v_num=44, val_loss=1.560, val_acc=0.325, val_PPL=4.770, train_acc=0.360, train_PPL=5.480, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 9:   0% 0/4 [00:00<00:00, -9892.23it/s, loss=1.73, v_num=44, val_loss=1.560, val_acc=0.325, val_PPL=4.770, train_acc=0.360, train_PPL=5.250, test_loss=1.580, test_acc=0.352, test_PPL=4.860] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  6.15it/s, loss=1.74, v_num=44, val_loss=1.520, val_acc=0.322, val_PPL=4.610, train_acc=0.360, train_PPL=5.250, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  5.73it/s, loss=1.74, v_num=44, val_loss=1.520, val_acc=0.322, val_PPL=4.610, train_acc=0.352, train_PPL=5.010, test_loss=1.580, test_acc=0.352, test_PPL=4.860]\n",
      "Testing DataLoader 0: 100% 2/2 [00:00<00:00,  9.43it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_PPL             5.115090847015381\n",
      "        test_acc            0.3163265287876129\n",
      "        test_loss           1.6274490356445312\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 2\n",
      "Epoch 0:   0% 0/4 [00:00<00:00, -16039.40it/s] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 0: 100% 4/4 [00:00<00:00,  5.87it/s, loss=1.74, v_num=44, val_loss=1.810, val_acc=0.109, val_PPL=6.140, train_acc=0.352, train_PPL=5.010, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 1:   0% 0/4 [00:00<00:00, -11765.23it/s, loss=1.74, v_num=44, val_loss=1.810, val_acc=0.109, val_PPL=6.140, train_acc=0.069, train_PPL=6.100, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 1: 100% 4/4 [00:00<00:00,  5.92it/s, loss=1.74, v_num=44, val_loss=1.810, val_acc=0.109, val_PPL=6.090, train_acc=0.069, train_PPL=6.100, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 2:   0% 0/4 [00:00<00:00, -11881.88it/s, loss=1.74, v_num=44, val_loss=1.810, val_acc=0.109, val_PPL=6.090, train_acc=0.126, train_PPL=6.020, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2: 100% 4/4 [00:00<00:00,  5.91it/s, loss=1.74, v_num=44, val_loss=1.800, val_acc=0.127, val_PPL=6.040, train_acc=0.126, train_PPL=6.020, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 3:   0% 0/4 [00:00<00:00, -7928.74it/s, loss=1.74, v_num=44, val_loss=1.800, val_acc=0.127, val_PPL=6.040, train_acc=0.241, train_PPL=5.980, test_loss=1.630, test_acc=0.316, test_PPL=5.120] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3: 100% 4/4 [00:00<00:00,  4.96it/s, loss=1.74, v_num=44, val_loss=1.790, val_acc=0.127, val_PPL=5.990, train_acc=0.241, train_PPL=5.980, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 4:   0% 0/4 [00:00<00:00, -9927.35it/s, loss=1.74, v_num=44, val_loss=1.790, val_acc=0.127, val_PPL=5.990, train_acc=0.330, train_PPL=5.920, test_loss=1.630, test_acc=0.316, test_PPL=5.120] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4: 100% 4/4 [00:00<00:00,  6.20it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.155, val_PPL=5.940, train_acc=0.330, train_PPL=5.920, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 5:   0% 0/4 [00:00<00:00, -10446.59it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.155, val_PPL=5.940, train_acc=0.330, train_PPL=5.840, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5: 100% 4/4 [00:00<00:00,  5.84it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.164, val_PPL=5.900, train_acc=0.330, train_PPL=5.840, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 6:   0% 0/4 [00:00<00:00, -10446.59it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.164, val_PPL=5.900, train_acc=0.341, train_PPL=5.730, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6: 100% 4/4 [00:00<00:00,  6.28it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.164, val_PPL=5.850, train_acc=0.341, train_PPL=5.730, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 7:   0% 0/4 [00:00<00:00, -9915.61it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.164, val_PPL=5.850, train_acc=0.345, train_PPL=5.630, test_loss=1.630, test_acc=0.316, test_PPL=5.120] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7: 100% 4/4 [00:00<00:00,  6.13it/s, loss=1.74, v_num=44, val_loss=1.760, val_acc=0.164, val_PPL=5.810, train_acc=0.345, train_PPL=5.630, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 8:   0% 0/4 [00:00<00:00, -9269.18it/s, loss=1.74, v_num=44, val_loss=1.760, val_acc=0.164, val_PPL=5.810, train_acc=0.345, train_PPL=5.500, test_loss=1.630, test_acc=0.316, test_PPL=5.120] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 8: 100% 4/4 [00:00<00:00,  6.13it/s, loss=1.74, v_num=44, val_loss=1.760, val_acc=0.164, val_PPL=5.820, train_acc=0.345, train_PPL=5.500, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 9:   0% 0/4 [00:00<00:00, -11570.49it/s, loss=1.74, v_num=44, val_loss=1.760, val_acc=0.164, val_PPL=5.820, train_acc=0.345, train_PPL=5.330, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  5.98it/s, loss=1.74, v_num=44, val_loss=1.800, val_acc=0.164, val_PPL=6.060, train_acc=0.345, train_PPL=5.330, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  5.59it/s, loss=1.74, v_num=44, val_loss=1.800, val_acc=0.164, val_PPL=6.060, train_acc=0.345, train_PPL=5.080, test_loss=1.630, test_acc=0.316, test_PPL=5.120]\n",
      "Testing DataLoader 0: 100% 2/2 [00:00<00:00, 10.12it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_PPL             5.319501876831055\n",
      "        test_acc            0.30612245202064514\n",
      "        test_loss           1.6663204431533813\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 3\n",
      "Epoch 0:   0% 0/4 [00:00<00:00, -16225.55it/s] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 19.84it/s]\u001B[A\n",
      "Epoch 0: 100% 4/4 [00:00<00:00,  6.07it/s, loss=1.74, v_num=44, val_loss=1.810, val_acc=0.110, val_PPL=6.080, train_acc=0.345, train_PPL=5.080, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 1:   0% 0/4 [00:00<00:00, -10936.91it/s, loss=1.74, v_num=44, val_loss=1.810, val_acc=0.110, val_PPL=6.080, train_acc=0.0766, train_PPL=6.110, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 12.86it/s]\u001B[A\n",
      "Epoch 1: 100% 4/4 [00:00<00:00,  4.72it/s, loss=1.74, v_num=44, val_loss=1.800, val_acc=0.0989, val_PPL=6.040, train_acc=0.0766, train_PPL=6.110, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 2:   0% 0/4 [00:00<00:00, -10824.01it/s, loss=1.74, v_num=44, val_loss=1.800, val_acc=0.0989, val_PPL=6.040, train_acc=0.115, train_PPL=6.020, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 2: 100% 4/4 [00:00<00:00,  6.11it/s, loss=1.74, v_num=44, val_loss=1.790, val_acc=0.0659, val_PPL=6.000, train_acc=0.115, train_PPL=6.020, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 3:   0% 0/4 [00:00<00:00, -9310.33it/s, loss=1.74, v_num=44, val_loss=1.790, val_acc=0.0659, val_PPL=6.000, train_acc=0.234, train_PPL=5.970, test_loss=1.670, test_acc=0.306, test_PPL=5.320] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3: 100% 4/4 [00:00<00:00,  6.15it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.0659, val_PPL=5.950, train_acc=0.234, train_PPL=5.970, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 4:   0% 0/4 [00:00<00:00, -10699.76it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.0659, val_PPL=5.950, train_acc=0.330, train_PPL=5.910, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 19.96it/s]\u001B[A\n",
      "Epoch 4: 100% 4/4 [00:00<00:00,  6.16it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.0769, val_PPL=5.910, train_acc=0.330, train_PPL=5.910, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 5:   0% 0/4 [00:00<00:00, -11570.49it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.0769, val_PPL=5.910, train_acc=0.330, train_PPL=5.810, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5: 100% 4/4 [00:00<00:00,  6.18it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.110, val_PPL=5.890, train_acc=0.330, train_PPL=5.810, test_loss=1.670, test_acc=0.306, test_PPL=5.320] \n",
      "Epoch 6:   0% 0/4 [00:00<00:00, -10082.46it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.110, val_PPL=5.890, train_acc=0.330, train_PPL=5.720, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6: 100% 4/4 [00:00<00:00,  6.30it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.110, val_PPL=5.870, train_acc=0.330, train_PPL=5.720, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 7:   0% 0/4 [00:00<00:00, -11290.19it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.110, val_PPL=5.870, train_acc=0.345, train_PPL=5.580, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7: 100% 4/4 [00:00<00:00,  6.04it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.110, val_PPL=5.910, train_acc=0.345, train_PPL=5.580, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 8:   0% 0/4 [00:00<00:00, -10591.68it/s, loss=1.74, v_num=44, val_loss=1.780, val_acc=0.110, val_PPL=5.910, train_acc=0.345, train_PPL=5.450, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 15.77it/s]\u001B[A\n",
      "Epoch 8: 100% 4/4 [00:00<00:00,  4.98it/s, loss=1.74, v_num=44, val_loss=1.820, val_acc=0.110, val_PPL=6.160, train_acc=0.345, train_PPL=5.450, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 9:   0% 0/4 [00:00<00:00, -11444.21it/s, loss=1.74, v_num=44, val_loss=1.820, val_acc=0.110, val_PPL=6.160, train_acc=0.345, train_PPL=5.220, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  6.41it/s, loss=1.73, v_num=44, val_loss=1.920, val_acc=0.110, val_PPL=6.820, train_acc=0.345, train_PPL=5.220, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  5.99it/s, loss=1.73, v_num=44, val_loss=1.920, val_acc=0.110, val_PPL=6.820, train_acc=0.345, train_PPL=5.010, test_loss=1.670, test_acc=0.306, test_PPL=5.320]\n",
      "Testing DataLoader 0: 100% 2/2 [00:00<00:00, 18.51it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_PPL             5.432380676269531\n",
      "        test_acc            0.30612245202064514\n",
      "        test_loss           1.6847655773162842\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "STARTING FOLD 4\n",
      "Epoch 0:   0% 0/4 [00:00<00:00, -15797.76it/s] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 18.13it/s]\u001B[A\n",
      "Epoch 0: 100% 4/4 [00:00<00:00,  4.92it/s, loss=1.73, v_num=44, val_loss=1.800, val_acc=0.0472, val_PPL=6.070, train_acc=0.345, train_PPL=5.010, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 1:   0% 0/4 [00:00<00:00, -10866.07it/s, loss=1.73, v_num=44, val_loss=1.800, val_acc=0.0472, val_PPL=6.070, train_acc=0.0728, train_PPL=6.100, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 19.00it/s]\u001B[A\n",
      "Epoch 1: 100% 4/4 [00:00<00:00,  4.59it/s, loss=1.73, v_num=44, val_loss=1.790, val_acc=0.226, val_PPL=6.000, train_acc=0.0728, train_PPL=6.100, test_loss=1.680, test_acc=0.306, test_PPL=5.430] \n",
      "Epoch 2:   0% 0/4 [00:00<00:00, -9068.77it/s, loss=1.73, v_num=44, val_loss=1.790, val_acc=0.226, val_PPL=6.000, train_acc=0.123, train_PPL=6.030, test_loss=1.680, test_acc=0.306, test_PPL=5.430] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0: 100% 2/2 [00:00<00:00, 17.70it/s]\u001B[A\n",
      "Epoch 2: 100% 4/4 [00:00<00:00,  5.84it/s, loss=1.73, v_num=44, val_loss=1.780, val_acc=0.307, val_PPL=5.940, train_acc=0.123, train_PPL=6.030, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 3:   0% 0/4 [00:00<00:00, -12087.33it/s, loss=1.73, v_num=44, val_loss=1.780, val_acc=0.307, val_PPL=5.940, train_acc=0.245, train_PPL=5.980, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 3: 100% 4/4 [00:00<00:00,  6.26it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.307, val_PPL=5.860, train_acc=0.245, train_PPL=5.980, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 4:   0% 0/4 [00:00<00:00, -11507.01it/s, loss=1.74, v_num=44, val_loss=1.770, val_acc=0.307, val_PPL=5.860, train_acc=0.326, train_PPL=5.920, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 4: 100% 4/4 [00:00<00:00,  6.05it/s, loss=1.74, v_num=44, val_loss=1.750, val_acc=0.307, val_PPL=5.770, train_acc=0.326, train_PPL=5.920, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 5:   0% 0/4 [00:00<00:00, -11586.48it/s, loss=1.74, v_num=44, val_loss=1.750, val_acc=0.307, val_PPL=5.770, train_acc=0.330, train_PPL=5.840, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 5: 100% 4/4 [00:00<00:00,  6.23it/s, loss=1.74, v_num=44, val_loss=1.740, val_acc=0.311, val_PPL=5.670, train_acc=0.330, train_PPL=5.840, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 6:   0% 0/4 [00:00<00:00, -10965.50it/s, loss=1.74, v_num=44, val_loss=1.740, val_acc=0.311, val_PPL=5.670, train_acc=0.330, train_PPL=5.720, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 6: 100% 4/4 [00:00<00:00,  6.26it/s, loss=1.74, v_num=44, val_loss=1.710, val_acc=0.316, val_PPL=5.560, train_acc=0.330, train_PPL=5.720, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 7:   0% 0/4 [00:00<00:00, -11848.32it/s, loss=1.74, v_num=44, val_loss=1.710, val_acc=0.316, val_PPL=5.560, train_acc=0.333, train_PPL=5.620, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 7: 100% 4/4 [00:00<00:00,  6.15it/s, loss=1.74, v_num=44, val_loss=1.690, val_acc=0.316, val_PPL=5.410, train_acc=0.333, train_PPL=5.620, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 8:   0% 0/4 [00:00<00:00, -11570.49it/s, loss=1.74, v_num=44, val_loss=1.690, val_acc=0.316, val_PPL=5.410, train_acc=0.337, train_PPL=5.480, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 8: 100% 4/4 [00:00<00:00,  6.08it/s, loss=1.74, v_num=44, val_loss=1.660, val_acc=0.316, val_PPL=5.240, train_acc=0.337, train_PPL=5.480, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 9:   0% 0/4 [00:00<00:00, -8363.52it/s, loss=1.74, v_num=44, val_loss=1.660, val_acc=0.316, val_PPL=5.240, train_acc=0.337, train_PPL=5.300, test_loss=1.680, test_acc=0.306, test_PPL=5.430] \n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\n",
      "Validation:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0% 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  6.10it/s, loss=1.74, v_num=44, val_loss=1.650, val_acc=0.316, val_PPL=5.210, train_acc=0.337, train_PPL=5.300, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Epoch 9: 100% 4/4 [00:00<00:00,  5.67it/s, loss=1.74, v_num=44, val_loss=1.650, val_acc=0.316, val_PPL=5.210, train_acc=0.337, train_PPL=5.050, test_loss=1.680, test_acc=0.306, test_PPL=5.430]\n",
      "Testing DataLoader 0: 100% 2/2 [00:00<00:00, 10.22it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_PPL             5.368322372436523\n",
      "        test_acc            0.29591837525367737\n",
      "        test_loss           1.6739943027496338\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Testing DataLoader 0: 100% 2/2 [00:00<00:00,  2.93it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    average test_acc        0.3163265287876129\n",
      "    average_test_loss       1.6348645687103271\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100% 5/5 [00:00<00:00, 13.69it/s]\n"
     ]
    }
   ],
   "source": [
    "! python main_2.py -f encoder_decoder_baseline.yaml"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYC1YNG1XLTW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1658141297050,
     "user_tz": -60,
     "elapsed": 81125,
     "user": {
      "displayName": "Sonia Mathews",
      "userId": "11348936089475052132"
     }
    },
    "outputId": "53822801-f9c0-4e90-97fe-9a3e60917e24"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "nOjv7nBIXLTW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! python main_2.py -f encoder_decoder_baseline.yaml"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qc-qHb1o7RBJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "results = np.load('inference_results/encoder_decoder_lstm/Encoder_Decoder_LSTM.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<numpy.lib.npyio.NpzFile at 0x190051c51f0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.lib.npyio.NpzFile"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "list_obj = results.files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['archive/data.pkl',\n 'archive/data/0',\n 'archive/data/1',\n 'archive/data/2',\n 'archive/data/3',\n 'archive/data/4',\n 'archive/data/5',\n 'archive/data/6',\n 'archive/data/7',\n 'archive/data/8',\n 'archive/data/9',\n 'archive/version']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archive/data/0\n",
      "b'\\x0e\\x08\\xdf;\\xa0\\x81_;J\\x9c<=X7\\x08=\\x00\\xed\\xd7;\\xbc^\\xef=\\xb2\\xff\\xbf<\\xc0S\\xb4:P\\x03\\xc4=\\x84\\x17\\x90=\\xfa\\x167\\xbdPG\\xc9=\"\\xbfq<\\xe4#\\xc4;\\xe2Z\\xe5=\\r\\xe9\\xab=\\x97\\xdb\\x9e\\xbd3\\x8f\\xb5=\\xdcb\\xae\\xbb\\x16\\xc3C<,\\xe8\\xaa=B\\x02\\x90=l\\xdf~\\xbdj\\x04\\xc1=\\xd0M\\xe99\\xf0\\xb6I<\\xcd\\xd8\\xe0=\\xe0\\xca\\xb2=\\x15[\\xb6\\xbd8\\xf4\\xb5=\\xe8\\xb3T\\xbc\\x14 v<\\xaa\\xd4\\xa8=V\\xea\\x92=\\xc4<\\x8f\\xbd#p\\xbe=J\\xbbW\\xbb\\xd4\\xa3^<\\xecA\\xdd=\\x8ex\\xb3=\\xaa=\\xc0\\xbd\\x7f\\x8a\\xb4=\\xa6_s\\xbcX\\x16}<X\\xf8\\xa6=\\'\\xb4\\x92=\\xf4\\x8d\\x95\\xbdWl\\xbc=>\\xc6\\x87\\xbbvs^<\\xda\\x03\\xdb={\\xd9\\xb2=L\\x05\\xc4\\xbd\\xe1h\\xb3=4\\x98y\\xbcH\\\\{<,\\xc4\\xa5=\\x12\\x04\\x92=\\xbb\\xf5\\x97\\xbd\\xf3O\\xbb=\\xf6\\x9e\\x8c\\xbb\\x96\\xbe[<\\xee\\xd9\\xd9=\\xe8=\\xb2=\\xbck\\xc5\\xbd,\\xcd\\xb2=\\xaaDz\\xbcxiy<\\xd8!\\xa5=\\x05\\x83\\x91=~\\xdd\\x98\\xbd$\\xd0\\xba=%\\xbe\\x8c\\xbb\\x92\\x07Z<\\x89Q\\xd9=[\\xe0\\xb1=\\x9b\\xef\\xc5\\xbdY\\x89\\xb2=r\\xfdy\\xbcB`x<\\xe1\\xd6\\xa4=\"=\\x91=Q4\\x99\\xbd\\xfa\\x9e\\xba=\\xc1D\\x8c\\xbbrCY<x\\x18\\xd9=\\x97\\xb2\\xb1=\\xdd\\x1f\\xc6\\xbd)p\\xb2=\\x84\\xb4y\\xbc\\x1c\\xf4w<:\\xb7\\xa4=\\x11\\x1d\\x91=fT\\x99\\xbd\\xb4\\x8e\\xba=\\x9e\\xeb\\x8b\\xbb\\x9c\\xfcX<\"\\x02\\xd9=\\x08\\x9f\\xb1=31\\xc6\\xbd*h\\xb2=>\\x88y\\xbc@\\xd0w<\\xa6\\xaa\\xa4=\\x08\\x10\\x91=\\xe1_\\x99\\xbdB\\x8a\\xba=A\\xba\\x8b\\xbb\\x1c\\xe8X<\\xc2\\xf9\\xd8=\\x89\\x97\\xb1=27\\xc6\\xbd f\\xb2=\\xfapy\\xbc2\\xc7w<\\xce\\xa5\\xa4=D\\x0b\\x91=\\xc6c\\x99\\xbdm\\x89\\xba=p\\xa1\\x8b\\xbbd\\xe4X<\\xac\\xf6\\xd8=\\xf2\\x94\\xb1=\\x1c9\\xc6\\xbd\\xcfe\\xb2=jey\\xbc2\\xc6w<\\xf2\\xa3\\xa4=\\xb3\\t\\x91=\\xf8d\\x99\\xbdw\\x89\\xba=[\\x95\\x8b\\xbb\\xe8\\xe4X<\\x84\\xf5\\xd8=$\\x94\\xb1=\\xa69\\xc6\\xbd\\xdbe\\xb2=\\x06`y\\xbc\\xe2\\xc6w<2\\xa3\\xa4=>\\t\\x91=He\\x99\\xbd\\x98\\x89\\xba=\\xd1\\x8f\\x8b\\xbb\\xc8\\xe5X<\\r\\xf5\\xd8=\\xee\\x93\\xb1=\\xc39\\xc6\\xbd\\xf0e\\xb2=t]y\\xbc\\x9a\\xc7w<\\xe4\\xa2\\xa4=\"\\t\\x91=Ue\\x99\\xbd\\xb0\\x89\\xba=2\\x8d\\x8b\\xbbn\\xe6X<\\xdb\\xf4\\xd8=\\xe4\\x93\\xb1=\\xc69\\xc6\\xbd\\xfae\\xb2=T\\\\y\\xbc\\x00\\xc8w<\\xbf\\xa2\\xa4=\\x1e\\t\\x91=Se\\x99\\xbd\\xba\\x89\\xba=\\n\\x8c\\x8b\\xbb\\xb8\\xe6X<\\xc5\\xf4\\xd8=\\xe2\\x93\\xb1=\\xc29\\xc6\\xbd\\xfee\\xb2=\\xcc[y\\xbc,\\xc8w<\\xae\\xa2\\xa4=\\x1e\\t\\x91=Oe\\x99\\xbd\\xbe\\x89\\xba=u\\x8b\\x8b\\xbb\\xd2\\xe6X<\\xb8\\xf4\\xd8=\\xe3\\x93\\xb1=\\xbe9\\xc6\\xbd\\x01f\\xb2=\\x96[y\\xbc:\\xc8w<\\xa4\\xa2\\xa4= \\t\\x91=Me\\x99\\xbd\\xbe\\x89\\xba=G\\x8b\\x8b\\xbb\\xe6\\xe6X<\\xb4\\xf4\\xd8=\\xe2\\x93\\xb1=\\xbb9\\xc6\\xbd\\x01f\\xb2=\\x80[y\\xbcL\\xc8w<\\xa2\\xa2\\xa4= \\t\\x91=Ke\\x99\\xbd\\xbe\\x89\\xba=\\r\\x8b\\x8b\\xbb\\xec\\xe6X<\\xb2\\xf4\\xd8=\\xe4\\x93\\xb1=\\xba9\\xc6\\xbd\\x00f\\xb2=d[y\\xbcH\\xc8w<\\xa0\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\xeb\\x8a\\x8b\\xbb\\xe4\\xe6X<\\xaf\\xf4\\xd8=\\xe5\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=h[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\xf9\\x8a\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x01f\\xb2=p[y\\xbcF\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe2\\xe6X<\\xb0\\xf4\\xd8=\\xe4\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbcH\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Ke\\x99\\xbd\\xbf\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=l[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x02\\x8b\\x8b\\xbb\\xe6\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=\\\\[y\\xbcN\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x0b\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xaf\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbc@\\xc8w<\\x9e\\xa2\\xa4=!\\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe6\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4=!\\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe6\\xe6X<\\xb1\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbcF\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe4\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbcF\\xc8w<\\xa0\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbcF\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe4\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=p[y\\xbcF\\xc8w<\\xa0\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcF\\xc8w<\\x9f\\xa2\\xa4=!\\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcF\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4=!\\t\\x91=Je\\x99\\xbd\\xbd\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcH\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcF\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe4\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4=!\\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcH\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\x01\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4=!\\t\\x91=Je\\x99\\xbd\\xbd\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9f\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcB\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xe8\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=t[y\\xbcD\\xc8w<\\x9e\\xa2\\xa4= \\t\\x91=Je\\x99\\xbd\\xbe\\x89\\xba=\\t\\x8b\\x8b\\xbb\\xea\\xe6X<\\xb0\\xf4\\xd8=\\xe6\\x93\\xb1=\\xb99\\xc6\\xbd\\x00f\\xb2=\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "for item in list_obj[1:]:\n",
    "    print(item)\n",
    "    print(results[item])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "main.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}